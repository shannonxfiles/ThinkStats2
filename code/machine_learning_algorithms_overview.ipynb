{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linear Regression\n",
    "\n",
    "Used to estimate real values (cost of houses, number of calls, etc) based on continuous variables\n",
    "Establish relationship between independent and dependent variables by fitting a best line.\n",
    "The best fit line is known as the regression line and represented by equation: Y = a*X + b\n",
    "Y – Dependent Variable\n",
    "a – Slope\n",
    "X – Independent variable\n",
    "b – Intercept\n",
    "\n",
    "Two types of linear regression:\n",
    "* Simple Linear Regression - one independent variable\n",
    "* Multiple Linear Regression - more than one independent variable\n",
    "\"\"\"\n",
    "\n",
    "#Import Library\n",
    "#Import other necessary libraries like pandas, numpy...\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Load Train and Test datasets\n",
    "#Identify feature and response variable(s) and values must be numeric and numpy arrays\n",
    "x_train=input_variables_values_training_datasets\n",
    "y_train=target_variables_values_training_datasets\n",
    "x_test=input_variables_values_test_datasets\n",
    "\n",
    "# Create linear regression object\n",
    "linear = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "linear.fit(x_train, y_train)\n",
    "linear.score(x_train, y_train)\n",
    "\n",
    "#Equation coefficient and Intercept\n",
    "print('Coefficient: \\n', linear.coef_)\n",
    "print('Intercept: \\n', linear.intercept_)\n",
    "\n",
    "#Predict Output\n",
    "predicted= linear.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Logistic Regression\n",
    "\n",
    "Classification algorithm\n",
    "It is used to estimate discrete values (binary 0/1, yes/no, true/false) based on a given set of independent variable(s)\n",
    "It predicts the probability of occurrence of an event by fitting data to a logit function (logitic function that returns an S shape curve), one of the best mathematical ways to replicate a step function\n",
    "It predicts probability, so its output value is between 0 and 1 (probability you will solve a puzzle, etc.)\n",
    "\"\"\"\n",
    "\n",
    "#Import Library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create logistic regression object\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "model.score(X, y)\n",
    "\n",
    "#Equation coefficient and Intercept\n",
    "print('Coefficient: \\n', model.coef_)\n",
    "print('Intercept: \\n', model.intercept_)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Decision Tree\n",
    "\n",
    "Supervised learning algorithm that is mostly used for classification problems.\n",
    "Works for both categorical and continuous dependent variables\n",
    "The algorithm splits the population into two or more homogeneous sets, by determining the most significant attributes or independent variables, makes the groups as distinct as possible\n",
    "Divide the population in as different groups as possible\n",
    "\"\"\"\n",
    "\n",
    "#Import Library\n",
    "#Import other necessary libraries like pandas, numpy...\n",
    "from sklearn import tree\n",
    "\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create tree object \n",
    "model = tree.DecisionTreeClassifier(criterion='gini') # for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini  \n",
    "\n",
    "# model = tree.DecisionTreeRegressor() for regression\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "model.score(X, y)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Support Vector Machine (SVM)\n",
    "\n",
    "Classification method\n",
    "Algorithm plots each data item as a point in n dimensional space (where n is num features) with the value of each feature being the value of a particular coordinate\n",
    "Line is found that splits the data into two differently classified groups (line is the classifier)\n",
    "\"\"\"\n",
    "\n",
    "#Import Library\n",
    "from sklearn import svm\n",
    "\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.svc() # there is various option associated with it, this is simple for classification. You can refer link, for mo# re detail.\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "model.score(X, y)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive Bayes\n",
    "\n",
    "Classification technique based on Bayes' theorem with an assumption of independence between predictors\n",
    "A Naive Bayes classifier assumes that the presense of a particular feature in a class is unrelated to the presence of any other feature\n",
    "Features independently contribute to probability\n",
    "Useful for large data sets, usually outperforms more sophisticated classification methods\n",
    "\"\"\"\n",
    "\n",
    "#Import Library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object model = GaussianNB() # there is other distribution for multinomial classes like Bernoulli Naive Bayes, Refer link\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K-Nearest Neighbors (KNN)\n",
    "\n",
    "Can be used for both classification and regression, more widely used for classification\n",
    "KNN is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors\n",
    "The case asisgned to the class is most common amongst its K nearest neighbors, measured by a distance function\n",
    "\n",
    "KNN is computationally expensive\n",
    "Variables should be normalized else higher range variables can bias it\n",
    "Works on pre-processing stage more before going for KNN like outlier, noise removal\n",
    "\"\"\"\n",
    "\n",
    "#Import Library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create KNeighbors classifier object model \n",
    "KNeighborsClassifier(n_neighbors=6) # default value for n_neighbors is 5\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
